{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a384b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6053c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cf4f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac3c28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64be1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_texts, train_labels, test_labels = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "encodings = tokenizer(\n",
    "    list(train_text),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "train_labels = torch.tensor(list(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a12634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f79d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetDataset(encodings, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d06c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c68fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5839\n",
      "Loss: 0.5202\n",
      "Loss: 0.5966\n",
      "Loss: 0.6829\n",
      "Loss: 0.6250\n",
      "Loss: 0.5075\n",
      "Loss: 0.5388\n",
      "Loss: 0.3320\n",
      "Loss: 0.8510\n",
      "Loss: 0.6195\n",
      "Loss: 0.7686\n",
      "Loss: 0.4692\n",
      "Loss: 0.4630\n",
      "Loss: 0.4105\n",
      "Loss: 0.3445\n",
      "Loss: 0.5447\n",
      "Loss: 0.4637\n",
      "Loss: 0.5097\n",
      "Loss: 0.6369\n",
      "Loss: 0.4873\n",
      "Loss: 0.3478\n",
      "Loss: 0.5470\n",
      "Loss: 0.4272\n",
      "Loss: 0.4477\n",
      "Loss: 0.1620\n",
      "Loss: 0.5176\n",
      "Loss: 0.7186\n",
      "Loss: 0.3086\n",
      "Loss: 0.6826\n",
      "Loss: 0.3337\n",
      "Loss: 0.4256\n",
      "Loss: 0.6674\n",
      "Loss: 0.2074\n",
      "Loss: 0.2918\n",
      "Loss: 0.2309\n",
      "Loss: 0.3421\n",
      "Loss: 0.3959\n",
      "Loss: 0.6157\n",
      "Loss: 0.2824\n",
      "Loss: 0.6359\n",
      "Loss: 0.3064\n",
      "Loss: 0.4443\n",
      "Loss: 0.4194\n",
      "Loss: 0.3326\n",
      "Loss: 0.9103\n",
      "Loss: 0.6632\n",
      "Loss: 0.6336\n",
      "Loss: 0.5164\n",
      "Loss: 0.2883\n",
      "Loss: 0.3287\n",
      "Loss: 0.3523\n",
      "Loss: 0.4071\n",
      "Loss: 0.2215\n",
      "Loss: 0.3651\n",
      "Loss: 0.4121\n",
      "Loss: 0.6252\n",
      "Loss: 0.6765\n",
      "Loss: 0.5286\n",
      "Loss: 0.3750\n",
      "Loss: 0.4144\n",
      "Loss: 0.5483\n",
      "Loss: 0.4361\n",
      "Loss: 0.3055\n",
      "Loss: 0.3823\n",
      "Loss: 0.4681\n",
      "Loss: 0.3412\n",
      "Loss: 0.6217\n",
      "Loss: 0.5356\n",
      "Loss: 0.5770\n",
      "Loss: 0.3800\n",
      "Loss: 0.4267\n",
      "Loss: 0.4374\n",
      "Loss: 0.2637\n",
      "Loss: 0.4492\n",
      "Loss: 0.5294\n",
      "Loss: 0.4406\n",
      "Loss: 0.4577\n",
      "Loss: 0.5346\n",
      "Loss: 0.4741\n",
      "Loss: 0.5985\n",
      "Loss: 0.5341\n",
      "Loss: 0.4928\n",
      "Loss: 0.4320\n",
      "Loss: 0.6044\n",
      "Loss: 0.2338\n",
      "Loss: 0.7213\n",
      "Loss: 0.6202\n",
      "Loss: 0.6121\n",
      "Loss: 0.5233\n",
      "Loss: 0.3855\n",
      "Loss: 0.3754\n",
      "Loss: 0.3586\n",
      "Loss: 0.5776\n",
      "Loss: 0.3559\n",
      "Loss: 0.3956\n",
      "Loss: 0.4282\n",
      "Loss: 0.6104\n",
      "Loss: 0.5970\n",
      "Loss: 0.7500\n",
      "Loss: 0.3951\n",
      "Loss: 0.2643\n",
      "Loss: 0.4944\n",
      "Loss: 0.1839\n",
      "Loss: 0.3626\n",
      "Loss: 0.5398\n",
      "Loss: 0.3000\n",
      "Loss: 0.3333\n",
      "Loss: 0.2661\n",
      "Loss: 0.2416\n",
      "Loss: 0.2720\n",
      "Loss: 0.2657\n",
      "Loss: 0.4960\n",
      "Loss: 0.3668\n",
      "Loss: 0.3287\n",
      "Loss: 0.4205\n",
      "Loss: 0.3706\n",
      "Loss: 0.4091\n",
      "Loss: 0.4266\n",
      "Loss: 0.3445\n",
      "Loss: 0.5350\n",
      "Loss: 0.4584\n",
      "Loss: 0.3480\n",
      "Loss: 0.1354\n",
      "Loss: 0.2860\n",
      "Loss: 0.4439\n",
      "Loss: 0.5166\n",
      "Loss: 0.3428\n",
      "Loss: 0.5050\n",
      "Loss: 0.6953\n",
      "Loss: 0.2107\n",
      "Loss: 0.3348\n",
      "Loss: 0.2379\n",
      "Loss: 0.4592\n",
      "Loss: 0.5540\n",
      "Loss: 0.2774\n",
      "Loss: 0.3162\n",
      "Loss: 0.4709\n",
      "Loss: 0.3802\n",
      "Loss: 0.2815\n",
      "Loss: 0.3357\n",
      "Loss: 0.5221\n",
      "Loss: 0.4007\n",
      "Loss: 0.5209\n",
      "Loss: 0.2877\n",
      "Loss: 0.5497\n",
      "Loss: 0.5441\n",
      "Loss: 0.5340\n",
      "Loss: 0.5427\n",
      "Loss: 0.3451\n",
      "Loss: 0.4092\n",
      "Loss: 0.4042\n",
      "Loss: 0.4419\n",
      "Loss: 0.3559\n",
      "Loss: 0.4895\n",
      "Loss: 0.3721\n",
      "Loss: 0.4694\n",
      "Loss: 0.2996\n",
      "Loss: 0.3367\n",
      "Loss: 0.3447\n",
      "Loss: 0.5278\n",
      "Loss: 0.5100\n",
      "Loss: 0.2153\n",
      "Loss: 0.4743\n",
      "Loss: 0.5101\n",
      "Loss: 0.4631\n",
      "Loss: 0.4528\n",
      "Loss: 0.2807\n",
      "Loss: 0.8085\n",
      "Loss: 0.4941\n",
      "Loss: 0.5881\n",
      "Loss: 0.3246\n",
      "Loss: 0.5428\n",
      "Loss: 0.1668\n",
      "Loss: 0.4013\n",
      "Loss: 0.3411\n",
      "Loss: 0.3219\n",
      "Loss: 0.6358\n",
      "Loss: 0.2895\n",
      "Loss: 0.6739\n",
      "Loss: 0.1697\n",
      "Loss: 0.5486\n",
      "Loss: 0.7550\n",
      "Loss: 0.4135\n",
      "Loss: 0.5113\n",
      "Loss: 0.5107\n",
      "Loss: 0.3739\n",
      "Loss: 0.4203\n",
      "Loss: 0.3802\n",
      "Loss: 0.4078\n",
      "Loss: 0.5046\n",
      "Loss: 0.3604\n",
      "Loss: 0.3606\n",
      "Loss: 0.6340\n",
      "Loss: 0.3994\n",
      "Loss: 0.5654\n",
      "Loss: 0.2102\n",
      "Loss: 0.3732\n",
      "Loss: 0.3399\n",
      "Loss: 0.4824\n",
      "Loss: 0.4094\n",
      "Loss: 0.8363\n",
      "Loss: 0.2112\n",
      "Loss: 0.4779\n",
      "Loss: 0.2845\n",
      "Loss: 0.5321\n",
      "Loss: 0.4177\n",
      "Loss: 0.3211\n",
      "Loss: 0.7267\n",
      "Loss: 0.4520\n",
      "Loss: 0.4374\n",
      "Loss: 0.6167\n",
      "Loss: 0.5101\n",
      "Loss: 0.4675\n",
      "Loss: 0.4142\n",
      "Loss: 0.3240\n",
      "Loss: 0.5474\n",
      "Loss: 0.5603\n",
      "Loss: 0.3844\n",
      "Loss: 0.4831\n",
      "Loss: 0.5484\n",
      "Loss: 0.3936\n",
      "Loss: 0.3852\n",
      "Loss: 0.4363\n",
      "Loss: 0.3552\n",
      "Loss: 0.3161\n",
      "Loss: 0.3472\n",
      "Loss: 0.1915\n",
      "Loss: 0.3212\n",
      "Loss: 0.6912\n",
      "Loss: 0.3567\n",
      "Loss: 0.2175\n",
      "Loss: 0.2452\n",
      "Loss: 0.8274\n",
      "Loss: 0.2351\n",
      "Loss: 0.4114\n",
      "Loss: 0.4408\n",
      "Loss: 0.3376\n",
      "Loss: 0.3891\n",
      "Loss: 0.3472\n",
      "Loss: 0.0987\n",
      "Loss: 0.3695\n",
      "Loss: 0.3484\n",
      "Loss: 0.5126\n",
      "Loss: 0.5162\n",
      "Loss: 0.4085\n",
      "Loss: 0.1949\n",
      "Loss: 0.1934\n",
      "Loss: 0.4246\n",
      "Loss: 0.1079\n",
      "Loss: 0.4984\n",
      "Loss: 0.4874\n",
      "Loss: 0.4111\n",
      "Loss: 0.3141\n",
      "Loss: 0.3876\n",
      "Loss: 0.5949\n",
      "Loss: 0.3874\n",
      "Loss: 0.1809\n",
      "Loss: 0.6483\n",
      "Loss: 0.5925\n",
      "Loss: 0.3007\n",
      "Loss: 0.5329\n",
      "Loss: 0.4098\n",
      "Loss: 0.5376\n",
      "Loss: 0.2393\n",
      "Loss: 0.2807\n",
      "Loss: 0.3509\n",
      "Loss: 0.4984\n",
      "Loss: 0.3230\n",
      "Loss: 0.6193\n",
      "Loss: 0.9173\n",
      "Loss: 0.3247\n",
      "Loss: 0.2382\n",
      "Loss: 0.2975\n",
      "Loss: 0.4403\n",
      "Loss: 0.5705\n",
      "Loss: 0.4308\n",
      "Loss: 0.4608\n",
      "Loss: 0.3750\n",
      "Loss: 0.5451\n",
      "Loss: 0.4026\n",
      "Loss: 0.6058\n",
      "Loss: 0.4341\n",
      "Loss: 0.4549\n",
      "Loss: 0.2725\n",
      "Loss: 0.4001\n",
      "Loss: 0.3312\n",
      "Loss: 0.5529\n",
      "Loss: 0.2777\n",
      "Loss: 0.4368\n",
      "Loss: 0.3541\n",
      "Loss: 0.3225\n",
      "Loss: 0.5130\n",
      "Loss: 0.3608\n",
      "Loss: 0.3849\n",
      "Loss: 0.5450\n",
      "Loss: 0.4349\n",
      "Loss: 0.1274\n",
      "Loss: 0.4228\n",
      "Loss: 0.4036\n",
      "Loss: 0.2998\n",
      "Loss: 0.1360\n",
      "Loss: 0.4564\n",
      "Loss: 0.5994\n",
      "Loss: 0.3964\n",
      "Loss: 0.4512\n",
      "Loss: 0.2295\n",
      "Loss: 0.6249\n",
      "Loss: 0.3033\n",
      "Loss: 0.2414\n",
      "Loss: 0.5035\n",
      "Loss: 0.3991\n",
      "Loss: 0.8730\n",
      "Loss: 0.4794\n",
      "Loss: 0.6962\n",
      "Loss: 0.3611\n",
      "Loss: 0.1276\n",
      "Loss: 0.2119\n",
      "Loss: 0.2988\n",
      "Loss: 0.2960\n",
      "Loss: 0.3995\n",
      "Loss: 0.2021\n",
      "Loss: 0.4471\n",
      "Loss: 0.2424\n",
      "Loss: 0.4714\n",
      "Loss: 0.2620\n",
      "Loss: 0.2493\n",
      "Loss: 0.4321\n",
      "Loss: 0.2883\n",
      "Loss: 0.4083\n",
      "Loss: 0.1804\n",
      "Loss: 0.4317\n",
      "Loss: 0.4739\n",
      "Loss: 0.1812\n",
      "Loss: 0.4007\n",
      "Loss: 0.1539\n",
      "Loss: 0.2664\n",
      "Loss: 0.0951\n",
      "Loss: 0.2134\n",
      "Loss: 0.3809\n",
      "Loss: 0.2669\n",
      "Loss: 0.2621\n",
      "Loss: 0.5582\n",
      "Loss: 1.2113\n",
      "Loss: 0.1598\n",
      "Loss: 0.3404\n",
      "Loss: 0.2412\n",
      "Loss: 0.3014\n",
      "Loss: 0.6518\n",
      "Loss: 0.2849\n",
      "Loss: 0.2485\n",
      "Loss: 0.5283\n",
      "Loss: 0.7097\n",
      "Loss: 0.3042\n",
      "Loss: 0.2714\n",
      "Loss: 0.3027\n",
      "Loss: 0.6547\n",
      "Loss: 0.2801\n",
      "Loss: 0.4392\n",
      "Loss: 0.3645\n",
      "Loss: 0.4632\n",
      "Loss: 0.3313\n",
      "Loss: 0.4461\n",
      "Loss: 0.2129\n",
      "Loss: 0.4017\n",
      "Loss: 0.6287\n",
      "Loss: 0.6174\n",
      "Loss: 0.5569\n",
      "Loss: 0.3726\n",
      "Loss: 0.6422\n",
      "Loss: 0.6769\n",
      "Loss: 0.1820\n",
      "Loss: 0.4031\n",
      "Loss: 0.3787\n",
      "Loss: 0.4114\n",
      "Loss: 0.2461\n",
      "Loss: 0.3675\n",
      "Loss: 0.8150\n",
      "Loss: 0.3849\n",
      "Loss: 0.6386\n",
      "Loss: 0.7212\n",
      "Loss: 0.2846\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for batch in train_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78848542",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(\n",
    "    list(test_texts),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "test_labels = torch.tensor(list(test_labels))\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53cf67e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17889a",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1035f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8972c8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e82809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test[['id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13ef520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "0         0                 Just happened a terrible car crash\n",
       "1         2  Heard about #earthquake is different cities, s...\n",
       "2         3  there is a forest fire at spot pond, geese are...\n",
       "3         9           Apocalypse lighting. #Spokane #wildfires\n",
       "4        11      Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...     ...                                                ...\n",
       "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  10865  Storm in RI worse than last hurricane. My city...\n",
       "3260  10868  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  10875  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45d363c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(\n",
    "    list(test_df['text']),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28509a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "test_dataset = TestDataset(test_encodings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "111acc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49509f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': predictions\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15a59c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6d307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
